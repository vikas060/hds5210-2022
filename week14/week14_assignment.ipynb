{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Working with multiple data sets\n",
    "\n",
    "There are two data files that we'll be working with for this week's assignment.  They are described below.  Load those data files in with Pandas and then work to answering each of the questions below.\n",
    "\n",
    "## npidata.csv\n",
    "\n",
    "This file is basic information about every healthcare provider in the US.  It has one row for each NPI (National Provider Identifier).  It contains information such as the provider's name and address.\n",
    "\n",
    "\n",
    "## cmsYYYY.csv\n",
    "\n",
    "These are files about what kinds of procedures and patients providers in the US are serving under CMS programs, Medicare and Medicaid.  Each contains various statistics about providers over the course of a year.  There are three of these, for the years 2014, 2015, and 2016.  These files, however, don't contain information about the provider such as where the provider is located.\n",
    "\n",
    "## Our Goals\n",
    "\n",
    "For this assignment, we're going to want to compute some statistics based on the data in the **cms** files, but aggregate that data based on information in the **npidata** file.  As in last week's assignment, you'll need to store your answers in a variable called `answer` at the end of each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "01-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 1\n",
    "\n",
    "In this first step, we'll need to merge together all of the **cms** files into a single dataframe.  Be careful that these files might not be identical, so you'll have to look a little bit to figure out how to merge them.\n",
    "\n",
    "As you are merging them, make sure that you retain information about which file (i.e. which year) the data came from.  Call that new columns `year`.\n",
    "\n",
    "In your `answer` variable, provide a complete data frame that contains all of the rows and columns from the **cms** files, plus an additional column to store the year/file that particular row came from.\n",
    "\n",
    "The assertion tests will give you a good idea as to if you're merging the files correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "01-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "answer = None\n",
    "\n",
    "### SOLUTION\n",
    "cms_2014 = pd.read_csv('/../data/cms2014.csv')\n",
    "cms_2015 = pd.read_csv('/../data/cms2015.csv')\n",
    "cms_2016 = pd.read_csv('/../data/cms2016.csv')\n",
    "cms_2014.columns = cms_2014.columns.str.lower()\n",
    "cms_2015.columns = cms_2015.columns.str.lower()\n",
    "cms_2016.columns = cms_2016.columns.str.lower()\n",
    "CMS = [cms_2014, cms_2015, cms_2016]\n",
    "CMS = pd.concat(CMS, keys=[2014,2015,2016])\n",
    "cms = CMS.reset_index()\n",
    "cms.pop(\"level_1\")\n",
    "cms.rename(columns = {'level_0':'year'}, inplace = True)\n",
    "answer = cms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "01-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(answer.shape == (193862, 60))\n",
    "assert(list(answer['year'].unique()) == [2014,2015,2016])\n",
    "assert(set(answer.columns.str.lower()) == set(['year', 'nbr', 'npi', 'provider_type',\n",
    "       'medicare_participation_indicator', 'number_of_hcpcs', 'total_services',\n",
    "       'total_unique_benes', 'total_submitted_chrg_amt',\n",
    "       'total_medicare_allowed_amt', 'total_medicare_payment_amt',\n",
    "       'total_medicare_stnd_amt', 'drug_suppress_indicator',\n",
    "       'number_of_drug_hcpcs', 'total_drug_services',\n",
    "       'total_drug_unique_benes', 'total_drug_submitted_chrg_amt',\n",
    "       'total_drug_medicare_allowed_amt', 'total_drug_medicare_payment_amt',\n",
    "       'total_drug_medicare_stnd_amt', 'med_suppress_indicator',\n",
    "       'number_of_med_hcpcs', 'total_med_services', 'total_med_unique_benes',\n",
    "       'total_med_submitted_chrg_amt', 'total_med_medicare_allowed_amt',\n",
    "       'total_med_medicare_payment_amt', 'total_med_medicare_stnd_amt',\n",
    "       'beneficiary_average_age', 'beneficiary_age_less_65_count',\n",
    "       'beneficiary_age_65_74_count', 'beneficiary_age_75_84_count',\n",
    "       'beneficiary_age_greater_84_count', 'beneficiary_female_count',\n",
    "       'beneficiary_male_count', 'beneficiary_race_white_count',\n",
    "       'beneficiary_race_black_count', 'beneficiary_race_api_count',\n",
    "       'beneficiary_race_hispanic_count', 'beneficiary_race_natind_count',\n",
    "       'beneficiary_race_other_count', 'beneficiary_nondual_count',\n",
    "       'beneficiary_dual_count', 'beneficiary_cc_afib_percent',\n",
    "       'beneficiary_cc_alzrdsd_percent', 'beneficiary_cc_asthma_percent',\n",
    "       'beneficiary_cc_cancer_percent', 'beneficiary_cc_chf_percent',\n",
    "       'beneficiary_cc_ckd_percent', 'beneficiary_cc_copd_percent',\n",
    "       'beneficiary_cc_depr_percent', 'beneficiary_cc_diab_percent',\n",
    "       'beneficiary_cc_hyperl_percent', 'beneficiary_cc_hypert_percent',\n",
    "       'beneficiary_cc_ihd_percent', 'beneficiary_cc_ost_percent',\n",
    "       'beneficiary_cc_raoa_percent', 'beneficiary_cc_schiot_percent',\n",
    "       'beneficiary_cc_strk_percent', 'beneficiary_average_risk_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "02-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 2\n",
    "\n",
    "In this next part, we're going to join the **cms** data with the provider information in the **/data/npidata.csv** file.  In this join, we don't want to lose any records from the **cms** files, even if no matching provider exists in the **npidata** file.  However, we don't care about any providers from the **npidata** file that don't have records in the **cms** files.  Those providers can be ignored.\n",
    "\n",
    "Join the data files together to create one unified data frame called `answer`.  This dataframe should have all the columns from both **cms** and **npidata** files, joined together using the `npi` column.  \n",
    "\n",
    "Note that `npi` is unique in the **npidata** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "02-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "answer = None\n",
    "\n",
    "### SOLUTION\n",
    "npi = pd.read_csv('/data/npidata.csv')\n",
    "npi_data = cms.merge(npi, how='left', left_on='npi', right_on='NPI')\n",
    "answer = npi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "02-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "assert(answer.shape == (193862, 103))\n",
    "assert(list(answer['Provider Business Mailing Address State Name'].unique()) == ['IL','MO',numpy.nan,'WY'])\n",
    "assert(list(answer.groupby('Provider Business Mailing Address State Name').NPI.count()) == [111520, 53366, 4805])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "03-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 3\n",
    "\n",
    "If you did everything right above, you'll notice that grouping by a column with NaN in it will cause some rows to disappear from the aggregation test.  So, let's create a new column called `'State'` that has the same value as whatever is in the `'Provider Business Mailing Address State Name'` column or a value of `'XX'` if there is no state information.\n",
    "\n",
    "Set `answer` to be your final data frame with the new `'State'` column added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "03-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "answer = None\n",
    "\n",
    "### SOLUTION\n",
    "npi_data['State'] = npi_data['Provider Business Mailing Address State Name'].fillna('XX')\n",
    "answer = npi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "03-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(list(answer.groupby('State').npi.count()) == [111520, 53366, 4805, 24171])\n",
    "assert(answer.shape == (193862, 104))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "04-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 4\n",
    "\n",
    "Next, let's summarize the data by year and by State.  Create a pivot table that contains one row for each state and one column for each year.  Within the pivot table, put a sum of total services as the values.\n",
    "\n",
    "Assign `answer` to be that resulting pivot table.  In the tests, I'm going to plot a bar chart of your pivot table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "04-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "answer = None\n",
    "\n",
    "### SOLUTION\n",
    "answer = npi_data.pivot_table(values='total_services', index='State', columns='year', aggfunc=np.ma.sum, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "04-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(answer.shape == (4,3))\n",
    "assert(answer.sum().sum() == 519185664.7)\n",
    "assert(answer[2016].sum() == 176596933.8)\n",
    "assert(answer.loc['WY'].sum() == 10892707.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "answer.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "In order to submit your work, you'll need to use the `git` command line program to **add** your homework file (this file) to your local repository, **commit** your changes to your local repository, and then **push** those changes up to github.com.  From there, I'll be able to **pull** the changes down and do my grading.  I'll provide some feedback, **commit** and **push** my comments back to you.  Next week, I'll show you how to **pull** down my comments.\n",
    "\n",
    "To run through everything one last time and submit your work:\n",
    "1. Use the `Kernel` -> `Restart Kernel and Run All Cells` menu option to run everything from top to bottom and stop here.\n",
    "2. Follow the instruction on the prompt below to either ssave and submit your work, or continue working.\n",
    "\n",
    "If anything fails along the way with this submission part of the process, let me know.  I'll help you troubleshoort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "a=input('''\n",
    "Are you ready to submit your work?\n",
    "1. Click the Save icon (or do Ctrl-S / Cmd-S)\n",
    "2. Type \"yes\" or \"no\" below\n",
    "3. Press Enter\n",
    "\n",
    "''')\n",
    "\n",
    "if a=='yes':\n",
    "    !git pull\n",
    "    !git add week14_assignment.ipynb\n",
    "    !git commit -a -m \"Submitting the week 14 programming assignment\"\n",
    "    !git push\n",
    "else:\n",
    "    print('''\n",
    "    \n",
    "OK. We can wait.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
